{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_nomic.embeddings import NomicEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "local_llm = \"llama3.2:3b-instruct-fp16\"\n",
    "llm = ChatOllama(model=local_llm,temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm,temperature=0,format=\"json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:384: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n",
      "Could not load the custom kernel for multi-scale deformable attention: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "c:\\Users\\ashis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    }
   ],
   "source": [
    "source = \"ambuja test-rotated.pdf\"  # document per local path or URL\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "\n",
    "# output: ## Docling Technical Report [...]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"scratch\")\n",
    "with (output_dir / f\"markdown.md\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(result.document.export_to_markdown())\n",
    "document_path = Path(\"scratch/markdown.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredMarkdownLoader(document_path)\n",
    "loaded_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(loaded_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\",inference_mode=\"local\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company's total revenue for FY 2016-17 and FY 2019-20 was not disclosed. The company has made allotment of 26,54,47,491 equity shares to Harmonia Trade and Investment Limited at a premium of ' 416.87 per share, increasing the promoter group's shareholding from 66.70% to 70.30%. The company has also entered into a definitive agreement for acquisition of a cement grinding unit in Tuticorin, Tamil Nadu on slump sale basis at a total value of ' 413.75 Crores.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "##Generating\n",
    "rag_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "\n",
    "Here is the context to use to answer the question:\n",
    "\n",
    "{context}\n",
    "\n",
    "Think Carefully about the above context.\n",
    "\n",
    "Now, review the user question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Provide an answer to this question using only the above context.\n",
    "\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "##post-prcessing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "question = \"How many independent directors are in the board?\"\n",
    "#Test\n",
    "docs_ret = retriever.invoke(question)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt,question=question)\n",
    "generation = llm.invoke([HumanMessage(content = rag_prompt_formatted)])\n",
    "print(generation.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
